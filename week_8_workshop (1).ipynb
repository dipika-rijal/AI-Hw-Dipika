{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQr8FXdUcsRE"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import f1_score, mean_squared_error\n",
        "from scipy.stats import randint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Wine dataset (3-class classification)\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target"
      ],
      "metadata": {
        "id": "T1FaomnzdaSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification split (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HqWAwFzsdiTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "f1_dt = f1_score(y_test, y_pred_dt, average=\"weighted\")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
        "\n",
        "print(\"Decision Tree F1 (weighted):\", f1_dt)\n",
        "print(\"Random Forest F1 (weighted):\", f1_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK-VphSSdiQS",
        "outputId": "683b8c32-06f4-42c3-97a7-1a5fe2152b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 (weighted): 0.9439974457215836\n",
            "Random Forest F1 (weighted): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification explanation**\n",
        "The Random Forest Classifier achieved a higher weighted F1 score than the single Decision Tree Classifier, so it performed better on the Wine classification task.\n",
        "\n",
        "Random Forest tends to outperform a single tree because it combines predictions from many trees trained on different bootstrap samples and feature subsets, which reduces overfitting and variance while keeping bias relatively low."
      ],
      "metadata": {
        "id": "4cNv0WUqVNe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression target (numeric version of class labels)\n",
        "y_reg = y.astype(float)\n",
        "\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train_r, y_train_r)\n",
        "y_pred_dt_r = dt_reg.predict(X_test_r)\n",
        "mse_dt = mean_squared_error(y_test_r, y_pred_dt_r)\n",
        "\n",
        "# Random Forest Regressor [web:13]\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "rf_reg.fit(X_train_r, y_train_r)\n",
        "y_pred_rf_r = rf_reg.predict(X_test_r)\n",
        "mse_rf = mean_squared_error(y_test_r, y_pred_rf_r)\n",
        "\n",
        "print(\"DT Regressor MSE:\", mse_dt)\n",
        "print(\"RF Regressor MSE:\", mse_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFht4SKndiNq",
        "outputId": "dc8b2b00-b7f8-4b70-f6e7-e3b40d9c9637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT Regressor MSE: 0.16666666666666666\n",
            "RF Regressor MSE: 0.06483333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "param_dist_reg = {\n",
        "    \"n_estimators\": randint(50, 300),          # number of trees\n",
        "    \"max_depth\": [None, 5, 10, 20, 30],        # tree depth\n",
        "    \"min_samples_split\": randint(2, 11)        # min samples split\n",
        "}\n",
        "\n",
        "rf_reg_base = RandomForestRegressor(random_state=42)\n",
        "\n",
        "rand_search_reg = RandomizedSearchCV(\n",
        "    estimator=rf_reg_base,\n",
        "    param_distributions=param_dist_reg,\n",
        "    n_iter=20,                     # number of random combos\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rand_search_reg.fit(X_train_r, y_train_r)\n",
        "\n",
        "print(\"Best RF regressor params:\", rand_search_reg.best_params_)\n",
        "best_rf_reg = rand_search_reg.best_estimator_\n",
        "\n",
        "# Evaluate tuned RF regressor\n",
        "y_pred_rf_best_r = best_rf_reg.predict(X_test_r)\n",
        "mse_rf_best = mean_squared_error(y_test_r, y_pred_rf_best_r)\n",
        "print(\"Tuned RF Regressor MSE:\", mse_rf_best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBUDro1bdiLd",
        "outputId": "3a20dc83-bb22-4278-9454-e75a33642d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF regressor params: {'max_depth': 20, 'min_samples_split': 3, 'n_estimators': 299}\n",
            "Tuned RF Regressor MSE: 0.061069208770968254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression explanation**\n",
        "\n",
        "The Random Forest Regressor achieved a lower mean squared error (MSE) than the Decision Tree Regressor, so it performed better at predicting the numeric labels.\n",
        "\n",
        "After hyperparameter tuning with RandomizedSearchCV, the tuned Random Forest Regressor obtained an even smaller MSE than the default model, because choosing better values for n_estimators, max_depth, and min_samples_split improved the balance between underfitting and overfitting."
      ],
      "metadata": {
        "id": "zWz4nbQMVB8K"
      }
    }
  ]
}